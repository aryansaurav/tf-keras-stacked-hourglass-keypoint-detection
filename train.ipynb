{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23bff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, sys, argparse\n",
    "import tensorflow.keras.backend as K\n",
    "#from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, TerminateOnNaN\n",
    "\n",
    "from hourglass.model import get_hourglass_model\n",
    "from hourglass.data import hourglass_dataset\n",
    "from hourglass.loss import get_loss\n",
    "from hourglass.callbacks import EvalCallBack, CheckpointCleanCallBack, EvalCallBackNew\n",
    "from common.utils import get_classes, get_matchpoints, get_model_type, optimize_tf_gpu\n",
    "from common.model_utils import get_optimizer\n",
    "\n",
    "# Try to enable Auto Mixed Precision on TF 2.0\n",
    "# os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "# os.environ['TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE'] = '1'\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "# optimize_tf_gpu(tf, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc045847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments parsed from command line can be set here\n",
    "# Model definition options:\n",
    "num_stacks=2\n",
    "mobile=True\n",
    "tiny=False\n",
    "model_input_shape=\"256x256\"\n",
    "weights_path=None\n",
    "\n",
    "# Data options\n",
    "dataset_path=\"data/mpii\"\n",
    "classes_path=\"configs/mpii_classes.txt\"\n",
    "matchpoint_path=\"configs/mpii_match_point.txt\"\n",
    "\n",
    "# Training options\n",
    "batch_size=8\n",
    "optimizer=\"RMSProp\"\n",
    "loss_type=\"mse\"\n",
    "learning_rate=5e-4\n",
    "decay_type=None\n",
    "mixed_precision=False\n",
    "init_epoch=0\n",
    "total_epoch=100\n",
    "gpu_num=1\n",
    "\n",
    "height, width = model_input_shape.split('x')\n",
    "model_input_shape = (int(height), int(width)) \n",
    "orig_img_shape = (1280, 720)    # Height and width in pixels of input images, can be read from file or manually specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75c517b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = (int(model_input_shape[0]/4), int(model_input_shape[1]/4))\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8e52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(args):\n",
    "log_dir = 'logs/000'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "if matchpoint_path:\n",
    "    matchpoints = get_matchpoints(matchpoint_path)\n",
    "else:\n",
    "    matchpoints = None\n",
    "\n",
    "# choose model type\n",
    "if tiny:\n",
    "    num_channels = 128\n",
    "else:\n",
    "    num_channels = 256\n",
    "\n",
    "if mixed_precision:\n",
    "    tf_major_version = float(tf.__version__[:3])\n",
    "    if tf_major_version >= 2.1:\n",
    "        # apply mixed_precision for valid TF version\n",
    "        from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        mixed_precision.set_policy(policy)\n",
    "    else:\n",
    "        raise ValueError('Tensorflow {} does not support mixed precision'.format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd50474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/val dataset\n",
    "train_generator = hourglass_dataset(dataset_path, batch_size, class_names,\n",
    "                                    input_shape=model_input_shape,\n",
    "                                    num_hgstack=num_stacks,\n",
    "                                    is_train=True,\n",
    "                                    with_meta=False,\n",
    "                                    matchpoints=matchpoints)\n",
    "\n",
    "num_train = train_generator.get_dataset_size()\n",
    "num_val = len(train_generator.get_val_annotations())\n",
    "\n",
    "model_type = get_model_type(num_stacks, mobile, tiny, model_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488cf40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def dataset_from_annotations(annotations, image_path, validation_set=False):\n",
    "\n",
    "    image_filenames = []\n",
    "    centers = []\n",
    "    keypoints = []\n",
    "    scales = []\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        image_filename = os.path.join(image_path, annotation['img_paths'])\n",
    "        center = np.array(annotation['objpos'])\n",
    "        keypoint = np.array(annotation['joint_self'])\n",
    "        scale = annotation['scale_provided']\n",
    "        \n",
    "        # adjust center/scale slightly to avoid cropping limbs\n",
    "\n",
    "        if center[0] != -1:\n",
    "            center[1] = center[1] + 15 * scale\n",
    "            scale = scale * 1.25\n",
    "        \n",
    "        if annotation['isValidation'] == validation_set:        \n",
    "            image_filenames.append(image_filename)\n",
    "            centers.append(center)\n",
    "            keypoints.append(keypoint)\n",
    "            scales.append(scale)\n",
    "        else:\n",
    "            pass\n",
    "    img_filenames = tf.convert_to_tensor(image_filenames)\n",
    "    img_centers = tf.convert_to_tensor(centers, dtype=tf.float32)\n",
    "    img_scales = tf.convert_to_tensor(scales, dtype=tf.float32)\n",
    "    img_keypoints = tf.convert_to_tensor(keypoints, dtype=tf.float32)\n",
    "    return image_filenames, centers, scales, keypoints\n",
    "  \n",
    "                 \n",
    "            \n",
    "    \n",
    "        \n",
    "# dataset with tf.data.Dataset and training using model.fit()\n",
    "json_file = \"data/mpii/annotations.json\"\n",
    "image_path = \"data/mpii/images/\"\n",
    "with open(json_file) as f:\n",
    "    annotations = json.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f797d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filenames, img_centers, img_scales, img_keypoints = dataset_from_annotations(annotations, image_path,validation_set=False)   \n",
    "tfdataset_train= tf.data.Dataset.from_tensor_slices((img_filenames, img_centers, img_scales, img_keypoints))\n",
    "\n",
    "img_filenames, img_centers, img_scales, img_keypoints = dataset_from_annotations(annotations, image_path,validation_set=True)      \n",
    "tfdataset_val= tf.data.Dataset.from_tensor_slices((img_filenames, img_centers, img_scales, img_keypoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8daf34e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from common.data_utils import generate_gt_heatmap, label_heatmap\n",
    "import inspect\n",
    "\n",
    "# converted_f = tf.autograph.to_graph(label_heatmap.python_function)\n",
    "# print(inspect.getsource(converted_f))\n",
    "# img_keypointsT[0].shape\n",
    "# generate_gt_heatmap(img_keypoints[0], (64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0dec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_utils import random_horizontal_flip, random_vertical_flip, random_brightness\n",
    "from common.data_utils import random_grayscale, random_chroma, random_contrast, random_sharpness, random_blur, random_histeq, random_rotate_angle\n",
    "from common.data_utils import crop_single_object, rotate_single_object, crop_image, normalize_image, transform_keypoints, generate_gt_heatmap\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def map_dataset_to_image_heatmaps(imagefile, center, scale, keypoints):\n",
    "            \n",
    "    img = tf.io.read_file(imagefile)\n",
    "    decoded_img = tf.io.decode_png(img, channels=3, dtype=tf.dtypes.uint8)\n",
    "#     orig_img_shape = decoded_img.shape\n",
    "    resized_img = tf.image.resize(decoded_img, model_input_shape)\n",
    "    image = resized_img\n",
    "    \n",
    "#     image = tf.expand_dims(resized_img, axis=0)\n",
    "\n",
    "\n",
    "#     img = tf.io.read_file(imagefile)\n",
    "#     if img.mode != 'RGB':\n",
    "#         img = img.convert('RGB')\n",
    "#     image = np.array(img)\n",
    "#     img.close()\n",
    "    \n",
    "#     image_shape = image.shape\n",
    "\n",
    "    rotate_angle = 0\n",
    "#     image = crop_image(image, center, scale, model_input_shape, rotate_angle)\n",
    "    \n",
    "    # transform keypoints to cropped image reference\n",
    "#     transformed_keypoints = transform_keypoints(keypoints, center, scale, output_shape, rotate_angle)\n",
    "\n",
    "        # in case we got an empty image, bypass the sample\n",
    "#     if image is None:\n",
    "#         return None, None, None\n",
    "    \n",
    "    # normalize image\n",
    "#     image = normalize_image(image, self.get_color_mean())\n",
    "\n",
    "\n",
    "\n",
    "    # Data Augmentation\n",
    "#     image, keypoints = crop_single_object(image, keypoints, center, scale, model_input_shape)\n",
    "    seed = tf.random.uniform(shape=[2], maxval=3, dtype=tf.int32)\n",
    "    image = tf.image.stateless_random_brightness(image, max_delta=0.95, seed=seed)\n",
    "    image = tf.image.stateless_random_contrast(image, lower=0.1, upper=0.9, seed=seed)\n",
    "    image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
    "    image = tf.image.stateless_random_jpeg_quality(image, 75, 95, seed)\n",
    "    image = tf.image.stateless_random_saturation(image, lower=0.5, upper=1.0, seed=seed)\n",
    "\n",
    "\n",
    "    # Rescale keypoints from original_img_shape to output_shape\n",
    "    resized_scale = tf.divide(orig_img_shape, model_input_shape)\n",
    "    resized_scale = tf.concat([resized_scale, [1]], 0)  # adding third dimension for visibility dimension in the keypoints \n",
    "    keypoints = tf.multiply(keypoints, resized_scale)\n",
    "\n",
    "    # generate ground truth keypoint heatmap\n",
    "    gt_heatmap = generate_gt_heatmap(keypoints, output_shape)\n",
    "\n",
    "    out_heatmaps = []\n",
    "    for m in range(num_stacks):\n",
    "        out_heatmaps.append(gt_heatmap)\n",
    "        \n",
    "    return (image, tf.stack(out_heatmaps, axis=-1))\n",
    "\n",
    "\n",
    "def map_dataset_to_image_heatmaps_val(imagefile, center, scale, keypoints):\n",
    "            \n",
    "    img = tf.io.read_file(imagefile)\n",
    "    decoded_img = tf.io.decode_png(img, channels=3)\n",
    "#     orig_img_shape = decoded_img.shape\n",
    "    resized_img = tf.image.resize(decoded_img, model_input_shape)\n",
    "    image = resized_img\n",
    "    \n",
    "#     image = tf.expand_dims(resized_img, axis=0)\n",
    "\n",
    "\n",
    "#     img = tf.io.read_file(imagefile)\n",
    "#     if img.mode != 'RGB':\n",
    "#         img = img.convert('RGB')\n",
    "#     image = np.array(img)\n",
    "#     img.close()\n",
    "    \n",
    "#     image_shape = image.shape\n",
    "\n",
    "    rotate_angle = 0\n",
    "#     image = crop_image(image, center, scale, model_input_shape, rotate_angle)\n",
    "    \n",
    "    # transform keypoints to cropped image reference\n",
    "#     transformed_keypoints = transform_keypoints(keypoints, center, scale, output_shape, rotate_angle)\n",
    "\n",
    "        # in case we got an empty image, bypass the sample\n",
    "#     if image is None:\n",
    "#         return None, None, None\n",
    "    \n",
    "    # normalize image\n",
    "#     image = normalize_image(image, self.get_color_mean())\n",
    "\n",
    "\n",
    "\n",
    "    # Data Augmentation\n",
    "#     image, keypoints = crop_single_object(image, keypoints, center, scale, model_input_shape)\n",
    "#     seed = tf.random.uniform(shape=[2], maxval=3, dtype=tf.int32)\n",
    "#     image = tf.image.stateless_random_brightness(image, max_delta=0.95, seed=seed)\n",
    "#     image = tf.image.stateless_random_contrast(image, lower=0.1, upper=0.9, seed=seed)\n",
    "#     image = tf.image.stateless_random_hue(image, 0.2, seed)\n",
    "#     image = tf.image.stateless_random_jpeg_quality(image, 75, 95, seed)\n",
    "#     image = tf.image.stateless_random_saturation(image, lower=0.5, upper=1.0, seed=seed)\n",
    "\n",
    "\n",
    "    # Rescale keypoints from original_img_shape to output_shape\n",
    "    resized_scale = tf.divide(orig_img_shape, output_shape)\n",
    "    resized_scale = tf.concat([resized_scale, [1]], 0)  # adding third dimension for visibility dimension in the keypoints \n",
    "    keypoints = tf.cast(tf.multiply(keypoints, resized_scale), dtype=tf.float32)\n",
    "\n",
    "    # generate ground truth keypoint heatmap\n",
    "#     gt_heatmap = generate_gt_heatmap(keypoints, output_shape)\n",
    "\n",
    "#     out_heatmaps = []\n",
    "#     for m in range(num_stacks):\n",
    "#         out_heatmaps.append(gt_heatmap)\n",
    "            \n",
    "#     return (image, tf.stack(out_heatmaps, axis=-1))\n",
    "\n",
    "    return (image, keypoints)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920f2fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'cond/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_1/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_1/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_1/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_1/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_2/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_2/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_2/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_2/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_3/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_3/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_3/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_3/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_4/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_4/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_4/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_4/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_5/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_5/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_5/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_5/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_6/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_6/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_6/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_6/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_7/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_7/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_7/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_7/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_8/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_8/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_9/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_9/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_9/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_9/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_10/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_10/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_10/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_10/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_11/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_11/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_11/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_11/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_12/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_12/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_12/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_12/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_13/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_13/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_13/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_13/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_14/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_14/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_14/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_14/Cast_3:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'cond_15/Cast:0' shape=() dtype=int32>, <tf.Tensor 'cond_15/Cast_1:0' shape=() dtype=int32>] [<tf.Tensor 'cond_15/Cast_2:0' shape=() dtype=int32>, <tf.Tensor 'cond_15/Cast_3:0' shape=() dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfdataset_mapped_train = tfdataset_train.map(map_dataset_to_image_heatmaps, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n",
    "tfdataset_mapped_val = tfdataset_val.map(map_dataset_to_image_heatmaps_val, num_parallel_calls=AUTOTUNE).batch(batch_size, drop_remainder=True).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f89825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks for training process\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, update_freq='batch')\n",
    "# eval_callback = EvalCallBack(log_dir, dataset_path, class_names, model_input_shape, model_type)\n",
    "eval_callback = EvalCallBackNew(log_dir, tfdataset_mapped_val, class_names, model_input_shape, model_type)\n",
    "checkpoint_clean = CheckpointCleanCallBack(log_dir, max_val_keep=5)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [tensorboard, eval_callback, terminate_on_nan, checkpoint_clean]\n",
    "# callbacks = [tensorboard, terminate_on_nan, checkpoint_clean]\n",
    "\n",
    "# prepare optimizer\n",
    "steps_per_epoch = max(1, num_train//batch_size)\n",
    "decay_steps = steps_per_epoch * (total_epoch - init_epoch)\n",
    "optimizer = get_optimizer(optimizer, learning_rate, decay_type=decay_type, decay_steps=decay_steps)\n",
    "#optimizer = RMSprop(lr=5e-4)\n",
    "\n",
    "# prepare loss function\n",
    "loss_func = get_loss(loss_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866ae498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mobile Stacked Hourglass model with stack number 2, channel number 256. train input shape (256, 256)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " front_conv_1x1_1 (Conv2D)      (None, 128, 128, 64  9472        ['image_input[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['front_conv_1x1_1[0][0]']       \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " front_residual_1_conv_1x1_1 (S  (None, 128, 128, 64  4224       ['batch_normalization[0][0]']    \n",
      " eparableConv2D)                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['front_residual_1_conv_1x1_1[0][\n",
      " rmalization)                   )                                0]']                             \n",
      "                                                                                                  \n",
      " front_residual_1_conv_3x3_2 (S  (None, 128, 128, 64  4736       ['batch_normalization_1[0][0]']  \n",
      " eparableConv2D)                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['front_residual_1_conv_3x3_2[0][\n",
      " rmalization)                   )                                0]']                             \n",
      "                                                                                                  \n",
      " front_residual_1_conv_1x1_3 (S  (None, 128, 128, 12  8384       ['batch_normalization_2[0][0]']  \n",
      " eparableConv2D)                8)                                                                \n",
      "                                                                                                  \n",
      " front_residual_1_skip (Separab  (None, 128, 128, 12  8384       ['batch_normalization[0][0]']    \n",
      " leConv2D)                      8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['front_residual_1_conv_1x1_3[0][\n",
      " rmalization)                   8)                               0]']                             \n",
      "                                                                                                  \n",
      " front_residual_1_add (Add)     (None, 128, 128, 12  0           ['front_residual_1_skip[0][0]',  \n",
      "                                8)                                'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 128)  0           ['front_residual_1_add[0][0]']   \n",
      "                                                                                                  \n",
      " front_residual_2_conv_1x1_1 (S  (None, 64, 64, 64)  8384        ['max_pooling2d[0][0]']          \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['front_residual_2_conv_1x1_1[0][\n",
      " rmalization)                                                    0]']                             \n",
      "                                                                                                  \n",
      " front_residual_2_conv_3x3_2 (S  (None, 64, 64, 64)  4736        ['batch_normalization_4[0][0]']  \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['front_residual_2_conv_3x3_2[0][\n",
      " rmalization)                                                    0]']                             \n",
      "                                                                                                  \n",
      " front_residual_2_conv_1x1_3 (S  (None, 64, 64, 128)  8384       ['batch_normalization_5[0][0]']  \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 128)  512        ['front_residual_2_conv_1x1_3[0][\n",
      " rmalization)                                                    0]']                             \n",
      "                                                                                                  \n",
      " front_residual_2_add (Add)     (None, 64, 64, 128)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " front_residual_3_conv_1x1_1 (S  (None, 64, 64, 128)  16640      ['front_residual_2_add[0][0]']   \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 128)  512        ['front_residual_3_conv_1x1_1[0][\n",
      " rmalization)                                                    0]']                             \n",
      "                                                                                                  \n",
      " front_residual_3_conv_3x3_2 (S  (None, 64, 64, 128)  17664      ['batch_normalization_7[0][0]']  \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 128)  512        ['front_residual_3_conv_3x3_2[0][\n",
      " rmalization)                                                    0]']                             \n",
      "                                                                                                  \n",
      " front_residual_3_conv_1x1_3 (S  (None, 64, 64, 256)  33152      ['batch_normalization_8[0][0]']  \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " front_residual_3_skip (Separab  (None, 64, 64, 256)  33152      ['front_residual_2_add[0][0]']   \n",
      " leConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 256)  1024       ['front_residual_3_conv_1x1_3[0][\n",
      " rmalization)                                                    0]']                             \n",
      "                                                                                                  \n",
      " front_residual_3_add (Add)     (None, 64, 64, 256)  0           ['front_residual_3_skip[0][0]',  \n",
      "                                                                  'batch_normalization_9[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " hg0_downsample_1_conv_1x1_1 (S  (None, 64, 64, 128)  33152      ['front_residual_3_add[0][0]']   \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 128)  512        ['hg0_downsample_1_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_1_conv_3x3_2 (S  (None, 64, 64, 128)  17664      ['batch_normalization_10[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 64, 128)  512        ['hg0_downsample_1_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_1_conv_1x1_3 (S  (None, 64, 64, 256)  33152      ['batch_normalization_11[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['hg0_downsample_1_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_1_add (Add)     (None, 64, 64, 256)  0           ['front_residual_3_add[0][0]',   \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 256)  0          ['hg0_downsample_1_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg0_downsample_2_conv_1x1_1 (S  (None, 32, 32, 128)  33152      ['max_pooling2d_1[0][0]']        \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 128)  512        ['hg0_downsample_2_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_2_conv_3x3_2 (S  (None, 32, 32, 128)  17664      ['batch_normalization_13[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 128)  512        ['hg0_downsample_2_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_2_conv_1x1_3 (S  (None, 32, 32, 256)  33152      ['batch_normalization_14[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 32, 256)  1024       ['hg0_downsample_2_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_2_add (Add)     (None, 32, 32, 256)  0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['hg0_downsample_2_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg0_downsample_4_conv_1x1_1 (S  (None, 16, 16, 128)  33152      ['max_pooling2d_2[0][0]']        \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 128)  512        ['hg0_downsample_4_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_4_conv_3x3_2 (S  (None, 16, 16, 128)  17664      ['batch_normalization_16[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 128)  512        ['hg0_downsample_4_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_4_conv_1x1_3 (S  (None, 16, 16, 256)  33152      ['batch_normalization_17[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 256)  1024       ['hg0_downsample_4_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_4_add (Add)     (None, 16, 16, 256)  0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)   0           ['hg0_downsample_4_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg0_downsample_8_conv_1x1_1 (S  (None, 8, 8, 128)   33152       ['max_pooling2d_3[0][0]']        \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_8_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_8_conv_3x3_2 (S  (None, 8, 8, 128)   17664       ['batch_normalization_19[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_8_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_8_conv_1x1_3 (S  (None, 8, 8, 256)   33152       ['batch_normalization_20[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 8, 8, 256)   1024        ['hg0_downsample_8_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg0_downsample_8_add (Add)     (None, 8, 8, 256)    0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_1_conv_1x1_1  (None, 8, 8, 128)   33152       ['hg0_downsample_8_add[0][0]']   \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_1_conv_1x1_1[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_1_conv_3x3_2  (None, 8, 8, 128)   17664       ['batch_normalization_25[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_1_conv_3x3_2[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_1_conv_1x1_3  (None, 8, 8, 256)   33152       ['batch_normalization_26[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 8, 8, 256)   1024        ['hg0_downsample_f8_1_conv_1x1_3[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_1_add (Add)  (None, 8, 8, 256)    0           ['hg0_downsample_8_add[0][0]',   \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_2_conv_1x1_1  (None, 8, 8, 128)   33152       ['hg0_downsample_f8_1_add[0][0]']\n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_2_conv_1x1_1[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_2_conv_3x3_2  (None, 8, 8, 128)   17664       ['batch_normalization_28[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_2_conv_3x3_2[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_2_conv_1x1_3  (None, 8, 8, 256)   33152       ['batch_normalization_29[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 8, 8, 256)   1024        ['hg0_downsample_f8_2_conv_1x1_3[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_2_add (Add)  (None, 8, 8, 256)    0           ['hg0_downsample_f8_1_add[0][0]',\n",
      "                                                                  'batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_3_conv_1x1_1  (None, 8, 8, 128)   33152       ['hg0_downsample_f8_2_add[0][0]']\n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_short_conv_1  (None, 8, 8, 128)   33152       ['hg0_downsample_8_add[0][0]']   \n",
      " x1_1 (SeparableConv2D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_3_conv_1x1_1[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_short_conv_1x\n",
      " ormalization)                                                   1_1[0][0]']                      \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_short_conv_1x1  (None, 16, 16, 128)  33152      ['hg0_downsample_4_add[0][0]']   \n",
      " _1 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_3_conv_3x3_2  (None, 8, 8, 128)   17664       ['batch_normalization_31[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_short_conv_3  (None, 8, 8, 128)   17664       ['batch_normalization_22[0][0]'] \n",
      " x3_2 (SeparableConv2D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 16, 16, 128)  512        ['hg0_upsample_f4_short_conv_1x1_\n",
      " ormalization)                                                   1[0][0]']                        \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_3_conv_3x3_2[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 128)   512         ['hg0_downsample_f8_short_conv_3x\n",
      " ormalization)                                                   3_2[0][0]']                      \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_short_conv_3x3  (None, 16, 16, 128)  17664      ['batch_normalization_34[0][0]'] \n",
      " _2 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hg0_downsample_f8_3_conv_1x1_3  (None, 8, 8, 256)   33152       ['batch_normalization_32[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_short_conv_1  (None, 8, 8, 256)   33152       ['batch_normalization_23[0][0]'] \n",
      " x1_3 (SeparableConv2D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 16, 128)  512        ['hg0_upsample_f4_short_conv_3x3_\n",
      " ormalization)                                                   2[0][0]']                        \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 8, 8, 256)   1024        ['hg0_downsample_f8_3_conv_1x1_3[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 8, 8, 256)   1024        ['hg0_downsample_f8_short_conv_1x\n",
      " ormalization)                                                   1_3[0][0]']                      \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_short_conv_1x1  (None, 16, 16, 256)  33152      ['batch_normalization_35[0][0]'] \n",
      " _3 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_3_add (Add)  (None, 8, 8, 256)    0           ['hg0_downsample_f8_2_add[0][0]',\n",
      "                                                                  'batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_downsample_f8_short_add (A  (None, 8, 8, 256)   0           ['hg0_downsample_8_add[0][0]',   \n",
      " dd)                                                              'batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 16, 16, 256)  1024       ['hg0_upsample_f4_short_conv_1x1_\n",
      " ormalization)                                                   3[0][0]']                        \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 256)    0           ['hg0_downsample_f8_3_add[0][0]',\n",
      "                                                                  'hg0_downsample_f8_short_add[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_short_add (Add  (None, 16, 16, 256)  0          ['hg0_downsample_4_add[0][0]',   \n",
      " )                                                                'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 16, 16, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 16, 256)  0           ['hg0_upsample_f4_short_add[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_merged_conv_1x  (None, 16, 16, 128)  33152      ['add_1[0][0]']                  \n",
      " 1_1 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_short_conv_1x1  (None, 32, 32, 128)  33152      ['hg0_downsample_2_add[0][0]']   \n",
      " _1 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 16, 16, 128)  512        ['hg0_upsample_f4_merged_conv_1x1\n",
      " ormalization)                                                   _1[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 32, 32, 128)  512        ['hg0_upsample_f2_short_conv_1x1_\n",
      " ormalization)                                                   1[0][0]']                        \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_merged_conv_3x  (None, 16, 16, 128)  17664      ['batch_normalization_37[0][0]'] \n",
      " 3_2 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_short_conv_3x3  (None, 32, 32, 128)  17664      ['batch_normalization_40[0][0]'] \n",
      " _2 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 16, 16, 128)  512        ['hg0_upsample_f4_merged_conv_3x3\n",
      " ormalization)                                                   _2[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 32, 32, 128)  512        ['hg0_upsample_f2_short_conv_3x3_\n",
      " ormalization)                                                   2[0][0]']                        \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_merged_conv_1x  (None, 16, 16, 256)  33152      ['batch_normalization_38[0][0]'] \n",
      " 1_3 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_short_conv_1x1  (None, 32, 32, 256)  33152      ['batch_normalization_41[0][0]'] \n",
      " _3 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 16, 16, 256)  1024       ['hg0_upsample_f4_merged_conv_1x1\n",
      " ormalization)                                                   _3[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 32, 32, 256)  1024       ['hg0_upsample_f2_short_conv_1x1_\n",
      " ormalization)                                                   3[0][0]']                        \n",
      "                                                                                                  \n",
      " hg0_upsample_f4_merged_add (Ad  (None, 16, 16, 256)  0          ['add_1[0][0]',                  \n",
      " d)                                                               'batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_short_add (Add  (None, 32, 32, 256)  0          ['hg0_downsample_2_add[0][0]',   \n",
      " )                                                                'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0          ['hg0_upsample_f4_merged_add[0][0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 256)  0           ['hg0_upsample_f2_short_add[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_merged_conv_1x  (None, 32, 32, 128)  33152      ['add_2[0][0]']                  \n",
      " 1_1 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_short_conv_1x1  (None, 64, 64, 128)  33152      ['hg0_downsample_1_add[0][0]']   \n",
      " _1 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 32, 32, 128)  512        ['hg0_upsample_f2_merged_conv_1x1\n",
      " ormalization)                                                   _1[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 64, 64, 128)  512        ['hg0_upsample_f1_short_conv_1x1_\n",
      " ormalization)                                                   1[0][0]']                        \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_merged_conv_3x  (None, 32, 32, 128)  17664      ['batch_normalization_43[0][0]'] \n",
      " 3_2 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_short_conv_3x3  (None, 64, 64, 128)  17664      ['batch_normalization_46[0][0]'] \n",
      " _2 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 32, 32, 128)  512        ['hg0_upsample_f2_merged_conv_3x3\n",
      " ormalization)                                                   _2[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 64, 64, 128)  512        ['hg0_upsample_f1_short_conv_3x3_\n",
      " ormalization)                                                   2[0][0]']                        \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_merged_conv_1x  (None, 32, 32, 256)  33152      ['batch_normalization_44[0][0]'] \n",
      " 1_3 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_short_conv_1x1  (None, 64, 64, 256)  33152      ['batch_normalization_47[0][0]'] \n",
      " _3 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 32, 32, 256)  1024       ['hg0_upsample_f2_merged_conv_1x1\n",
      " ormalization)                                                   _3[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 64, 64, 256)  1024       ['hg0_upsample_f1_short_conv_1x1_\n",
      " ormalization)                                                   3[0][0]']                        \n",
      "                                                                                                  \n",
      " hg0_upsample_f2_merged_add (Ad  (None, 32, 32, 256)  0          ['add_2[0][0]',                  \n",
      " d)                                                               'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_short_add (Add  (None, 64, 64, 256)  0          ['hg0_downsample_1_add[0][0]',   \n",
      " )                                                                'batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0          ['hg0_upsample_f2_merged_add[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 64, 64, 256)  0           ['hg0_upsample_f1_short_add[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_merged_conv_1x  (None, 64, 64, 128)  33152      ['add_3[0][0]']                  \n",
      " 1_1 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 64, 64, 128)  512        ['hg0_upsample_f1_merged_conv_1x1\n",
      " ormalization)                                                   _1[0][0]']                       \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_merged_conv_3x  (None, 64, 64, 128)  17664      ['batch_normalization_49[0][0]'] \n",
      " 3_2 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 64, 64, 128)  512        ['hg0_upsample_f1_merged_conv_3x3\n",
      " ormalization)                                                   _2[0][0]']                       \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_merged_conv_1x  (None, 64, 64, 256)  33152      ['batch_normalization_50[0][0]'] \n",
      " 1_3 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 64, 64, 256)  1024       ['hg0_upsample_f1_merged_conv_1x1\n",
      " ormalization)                                                   _3[0][0]']                       \n",
      "                                                                                                  \n",
      " hg0_upsample_f1_merged_add (Ad  (None, 64, 64, 256)  0          ['add_3[0][0]',                  \n",
      " d)                                                               'batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_conv_1x1_1 (Conv2D)        (None, 64, 64, 256)  65792       ['hg0_upsample_f1_merged_add[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 64, 64, 256)  1024       ['hg0_conv_1x1_1[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " hg0_conv_1x1_predict (Conv2D)  (None, 64, 64, 16)   4112        ['batch_normalization_52[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " hg0_conv_1x1_2 (Conv2D)        (None, 64, 64, 256)  65792       ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " hg0_conv_1x1_3 (Conv2D)        (None, 64, 64, 256)  4352        ['hg0_conv_1x1_predict[0][0]']   \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 64, 64, 256)  0           ['hg0_conv_1x1_2[0][0]',         \n",
      "                                                                  'hg0_conv_1x1_3[0][0]',         \n",
      "                                                                  'front_residual_3_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg1_downsample_1_conv_1x1_1 (S  (None, 64, 64, 128)  33152      ['add_4[0][0]']                  \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 64, 64, 128)  512        ['hg1_downsample_1_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_1_conv_3x3_2 (S  (None, 64, 64, 128)  17664      ['batch_normalization_53[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 64, 64, 128)  512        ['hg1_downsample_1_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_1_conv_1x1_3 (S  (None, 64, 64, 256)  33152      ['batch_normalization_54[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 64, 64, 256)  1024       ['hg1_downsample_1_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_1_add (Add)     (None, 64, 64, 256)  0           ['add_4[0][0]',                  \n",
      "                                                                  'batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 256)  0          ['hg1_downsample_1_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg1_downsample_2_conv_1x1_1 (S  (None, 32, 32, 128)  33152      ['max_pooling2d_4[0][0]']        \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 32, 32, 128)  512        ['hg1_downsample_2_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_2_conv_3x3_2 (S  (None, 32, 32, 128)  17664      ['batch_normalization_56[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 32, 32, 128)  512        ['hg1_downsample_2_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_2_conv_1x1_3 (S  (None, 32, 32, 256)  33152      ['batch_normalization_57[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 32, 32, 256)  1024       ['hg1_downsample_2_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_2_add (Add)     (None, 32, 32, 256)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 256)  0          ['hg1_downsample_2_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg1_downsample_4_conv_1x1_1 (S  (None, 16, 16, 128)  33152      ['max_pooling2d_5[0][0]']        \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 16, 16, 128)  512        ['hg1_downsample_4_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_4_conv_3x3_2 (S  (None, 16, 16, 128)  17664      ['batch_normalization_59[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 16, 16, 128)  512        ['hg1_downsample_4_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_4_conv_1x1_3 (S  (None, 16, 16, 256)  33152      ['batch_normalization_60[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 16, 16, 256)  1024       ['hg1_downsample_4_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_4_add (Add)     (None, 16, 16, 256)  0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 256)   0           ['hg1_downsample_4_add[0][0]']   \n",
      "                                                                                                  \n",
      " hg1_downsample_8_conv_1x1_1 (S  (None, 8, 8, 128)   33152       ['max_pooling2d_6[0][0]']        \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_8_conv_1x1_1[0][\n",
      " ormalization)                                                   0]']                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " hg1_downsample_8_conv_3x3_2 (S  (None, 8, 8, 128)   17664       ['batch_normalization_62[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_8_conv_3x3_2[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_8_conv_1x1_3 (S  (None, 8, 8, 256)   33152       ['batch_normalization_63[0][0]'] \n",
      " eparableConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 8, 8, 256)   1024        ['hg1_downsample_8_conv_1x1_3[0][\n",
      " ormalization)                                                   0]']                             \n",
      "                                                                                                  \n",
      " hg1_downsample_8_add (Add)     (None, 8, 8, 256)    0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_1_conv_1x1_1  (None, 8, 8, 128)   33152       ['hg1_downsample_8_add[0][0]']   \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_1_conv_1x1_1[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_1_conv_3x3_2  (None, 8, 8, 128)   17664       ['batch_normalization_68[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_1_conv_3x3_2[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_1_conv_1x1_3  (None, 8, 8, 256)   33152       ['batch_normalization_69[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 8, 8, 256)   1024        ['hg1_downsample_f8_1_conv_1x1_3[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_1_add (Add)  (None, 8, 8, 256)    0           ['hg1_downsample_8_add[0][0]',   \n",
      "                                                                  'batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_2_conv_1x1_1  (None, 8, 8, 128)   33152       ['hg1_downsample_f8_1_add[0][0]']\n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_2_conv_1x1_1[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_2_conv_3x3_2  (None, 8, 8, 128)   17664       ['batch_normalization_71[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_2_conv_3x3_2[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_2_conv_1x1_3  (None, 8, 8, 256)   33152       ['batch_normalization_72[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 8, 8, 256)   1024        ['hg1_downsample_f8_2_conv_1x1_3[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_2_add (Add)  (None, 8, 8, 256)    0           ['hg1_downsample_f8_1_add[0][0]',\n",
      "                                                                  'batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_3_conv_1x1_1  (None, 8, 8, 128)   33152       ['hg1_downsample_f8_2_add[0][0]']\n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_short_conv_1  (None, 8, 8, 128)   33152       ['hg1_downsample_8_add[0][0]']   \n",
      " x1_1 (SeparableConv2D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_3_conv_1x1_1[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_short_conv_1x\n",
      " ormalization)                                                   1_1[0][0]']                      \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_short_conv_1x1  (None, 16, 16, 128)  33152      ['hg1_downsample_4_add[0][0]']   \n",
      " _1 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_3_conv_3x3_2  (None, 8, 8, 128)   17664       ['batch_normalization_74[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_short_conv_3  (None, 8, 8, 128)   17664       ['batch_normalization_65[0][0]'] \n",
      " x3_2 (SeparableConv2D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 16, 16, 128)  512        ['hg1_upsample_f4_short_conv_1x1_\n",
      " ormalization)                                                   1[0][0]']                        \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_3_conv_3x3_2[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 8, 8, 128)   512         ['hg1_downsample_f8_short_conv_3x\n",
      " ormalization)                                                   3_2[0][0]']                      \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_short_conv_3x3  (None, 16, 16, 128)  17664      ['batch_normalization_77[0][0]'] \n",
      " _2 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_3_conv_1x1_3  (None, 8, 8, 256)   33152       ['batch_normalization_75[0][0]'] \n",
      "  (SeparableConv2D)                                                                               \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_short_conv_1  (None, 8, 8, 256)   33152       ['batch_normalization_66[0][0]'] \n",
      " x1_3 (SeparableConv2D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 16, 16, 128)  512        ['hg1_upsample_f4_short_conv_3x3_\n",
      " ormalization)                                                   2[0][0]']                        \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 256)   1024        ['hg1_downsample_f8_3_conv_1x1_3[\n",
      " ormalization)                                                   0][0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 8, 8, 256)   1024        ['hg1_downsample_f8_short_conv_1x\n",
      " ormalization)                                                   1_3[0][0]']                      \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_short_conv_1x1  (None, 16, 16, 256)  33152      ['batch_normalization_78[0][0]'] \n",
      " _3 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_3_add (Add)  (None, 8, 8, 256)    0           ['hg1_downsample_f8_2_add[0][0]',\n",
      "                                                                  'batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " hg1_downsample_f8_short_add (A  (None, 8, 8, 256)   0           ['hg1_downsample_8_add[0][0]',   \n",
      " dd)                                                              'batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 16, 16, 256)  1024       ['hg1_upsample_f4_short_conv_1x1_\n",
      " ormalization)                                                   3[0][0]']                        \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 256)    0           ['hg1_downsample_f8_3_add[0][0]',\n",
      "                                                                  'hg1_downsample_f8_short_add[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_short_add (Add  (None, 16, 16, 256)  0          ['hg1_downsample_4_add[0][0]',   \n",
      " )                                                                'batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 256)  0          ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 16, 256)  0           ['hg1_upsample_f4_short_add[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_merged_conv_1x  (None, 16, 16, 128)  33152      ['add_6[0][0]']                  \n",
      " 1_1 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_short_conv_1x1  (None, 32, 32, 128)  33152      ['hg1_downsample_2_add[0][0]']   \n",
      " _1 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 16, 16, 128)  512        ['hg1_upsample_f4_merged_conv_1x1\n",
      " ormalization)                                                   _1[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 32, 32, 128)  512        ['hg1_upsample_f2_short_conv_1x1_\n",
      " ormalization)                                                   1[0][0]']                        \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_merged_conv_3x  (None, 16, 16, 128)  17664      ['batch_normalization_80[0][0]'] \n",
      " 3_2 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_short_conv_3x3  (None, 32, 32, 128)  17664      ['batch_normalization_83[0][0]'] \n",
      " _2 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 16, 16, 128)  512        ['hg1_upsample_f4_merged_conv_3x3\n",
      " ormalization)                                                   _2[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 32, 32, 128)  512        ['hg1_upsample_f2_short_conv_3x3_\n",
      " ormalization)                                                   2[0][0]']                        \n",
      "                                                                                                  \n",
      " hg1_upsample_f4_merged_conv_1x  (None, 16, 16, 256)  33152      ['batch_normalization_81[0][0]'] \n",
      " 1_3 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_short_conv_1x1  (None, 32, 32, 256)  33152      ['batch_normalization_84[0][0]'] \n",
      " _3 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 16, 16, 256)  1024       ['hg1_upsample_f4_merged_conv_1x1\n",
      " ormalization)                                                   _3[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 32, 32, 256)  1024       ['hg1_upsample_f2_short_conv_1x1_\n",
      " ormalization)                                                   3[0][0]']                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " hg1_upsample_f4_merged_add (Ad  (None, 16, 16, 256)  0          ['add_6[0][0]',                  \n",
      " d)                                                               'batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_short_add (Add  (None, 32, 32, 256)  0          ['hg1_downsample_2_add[0][0]',   \n",
      " )                                                                'batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0          ['hg1_upsample_f4_merged_add[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 32, 32, 256)  0           ['hg1_upsample_f2_short_add[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_merged_conv_1x  (None, 32, 32, 128)  33152      ['add_7[0][0]']                  \n",
      " 1_1 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_short_conv_1x1  (None, 64, 64, 128)  33152      ['hg1_downsample_1_add[0][0]']   \n",
      " _1 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 32, 32, 128)  512        ['hg1_upsample_f2_merged_conv_1x1\n",
      " ormalization)                                                   _1[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 64, 64, 128)  512        ['hg1_upsample_f1_short_conv_1x1_\n",
      " ormalization)                                                   1[0][0]']                        \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_merged_conv_3x  (None, 32, 32, 128)  17664      ['batch_normalization_86[0][0]'] \n",
      " 3_2 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_short_conv_3x3  (None, 64, 64, 128)  17664      ['batch_normalization_89[0][0]'] \n",
      " _2 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 32, 32, 128)  512        ['hg1_upsample_f2_merged_conv_3x3\n",
      " ormalization)                                                   _2[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 64, 64, 128)  512        ['hg1_upsample_f1_short_conv_3x3_\n",
      " ormalization)                                                   2[0][0]']                        \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_merged_conv_1x  (None, 32, 32, 256)  33152      ['batch_normalization_87[0][0]'] \n",
      " 1_3 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_short_conv_1x1  (None, 64, 64, 256)  33152      ['batch_normalization_90[0][0]'] \n",
      " _3 (SeparableConv2D)                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 32, 32, 256)  1024       ['hg1_upsample_f2_merged_conv_1x1\n",
      " ormalization)                                                   _3[0][0]']                       \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 64, 64, 256)  1024       ['hg1_upsample_f1_short_conv_1x1_\n",
      " ormalization)                                                   3[0][0]']                        \n",
      "                                                                                                  \n",
      " hg1_upsample_f2_merged_add (Ad  (None, 32, 32, 256)  0          ['add_7[0][0]',                  \n",
      " d)                                                               'batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_short_add (Add  (None, 64, 64, 256)  0          ['hg1_downsample_1_add[0][0]',   \n",
      " )                                                                'batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 256)  0          ['hg1_upsample_f2_merged_add[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 64, 64, 256)  0           ['hg1_upsample_f1_short_add[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_merged_conv_1x  (None, 64, 64, 128)  33152      ['add_8[0][0]']                  \n",
      " 1_1 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 64, 64, 128)  512        ['hg1_upsample_f1_merged_conv_1x1\n",
      " ormalization)                                                   _1[0][0]']                       \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_merged_conv_3x  (None, 64, 64, 128)  17664      ['batch_normalization_92[0][0]'] \n",
      " 3_2 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 64, 64, 128)  512        ['hg1_upsample_f1_merged_conv_3x3\n",
      " ormalization)                                                   _2[0][0]']                       \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_merged_conv_1x  (None, 64, 64, 256)  33152      ['batch_normalization_93[0][0]'] \n",
      " 1_3 (SeparableConv2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 64, 64, 256)  1024       ['hg1_upsample_f1_merged_conv_1x1\n",
      " ormalization)                                                   _3[0][0]']                       \n",
      "                                                                                                  \n",
      " hg1_upsample_f1_merged_add (Ad  (None, 64, 64, 256)  0          ['add_8[0][0]',                  \n",
      " d)                                                               'batch_normalization_94[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " hg1_conv_1x1_1 (Conv2D)        (None, 64, 64, 256)  65792       ['hg1_upsample_f1_merged_add[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 64, 64, 256)  1024       ['hg1_conv_1x1_1[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " hg1_conv_1x1_predict (Conv2D)  (None, 64, 64, 16)   4112        ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " tf.stack (TFOpLambda)          (None, 64, 64, 16,   0           ['hg0_conv_1x1_predict[0][0]',   \n",
      "                                2)                                'hg1_conv_1x1_predict[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,782,112\n",
      "Trainable params: 2,750,240\n",
      "Non-trainable params: 31,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# support multi-gpu training\n",
    "if gpu_num >= 2:\n",
    "    # devices_list=[\"/gpu:0\", \"/gpu:1\"]\n",
    "    devices_list=[\"/gpu:{}\".format(n) for n in range(gpu_num)]\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=devices_list)\n",
    "    print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "    with strategy.scope():\n",
    "        # get multi-gpu train model. you can also use \"model_input_shape=None\" to create a dynamic input shape model,\n",
    "        # but multiscale train/inference doesn't work for it\n",
    "        model = get_hourglass_model(num_classes, num_stacks, num_channels, model_input_shape=model_input_shape, mobile=mobile)\n",
    "        # compile model\n",
    "        model.compile(optimizer=optimizer, loss=loss_func)\n",
    "else:\n",
    "    # get normal train model. you can also use \"model_input_shape=None\" to create a dynamic input shape model,\n",
    "    # but multiscale train/inference doesn't work for it\n",
    "    model = get_hourglass_model(num_classes, num_stacks, num_channels, model_input_shape=model_input_shape, mobile=mobile)\n",
    "    # compile model\n",
    "    model.compile(optimizer=optimizer, loss=loss_func)\n",
    "\n",
    "print('Create {} Stacked Hourglass model with stack number {}, channel number {}. train input shape {}'.format('Mobile' if mobile else '', num_stacks, num_channels, model_input_shape))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209ca08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if weights_path:\n",
    "#     model.load_weights(weights_path, by_name=True)#, skip_mismatch=True)\n",
    "#     print('Load weights {}.'.format(weights_path))\n",
    "\n",
    "# # start training\n",
    "# print('Train on {} samples, val on {} samples, with batch size {}, model input shape {}.'.format(num_train, num_val, batch_size, model_input_shape))\n",
    "# model.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=num_train // batch_size,\n",
    "#                     epochs=total_epoch,\n",
    "#                     initial_epoch=init_epoch,\n",
    "#                     workers=1,\n",
    "#                     use_multiprocessing=False,\n",
    "#                     max_queue_size=10,\n",
    "                    \n",
    "#                     callbacks=callbacks)\n",
    "\n",
    "# model.save(os.path.join(log_dir, 'trained_final.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd29ae61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 256, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item = next(iter(tfdataset_mapped_train))\n",
    "data_item[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c42635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing GPU device configuration\n",
    "# import tensorflow as tf\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# tf.config.set_logical_device_configuration(\n",
    "#     physical_devices[0],\n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=100),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=100)])\n",
    "# logical_devices = tf.config.list_logical_devices('GPU')\n",
    "# logical_devicesphysical_devices = tf.config.list_physical_devices('GPU')\n",
    "# try:\n",
    "#   tf.config.set_logical_device_configuration(\n",
    "#     physical_devices[0],\n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=100),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=100)])\n",
    "\n",
    "#   logical_devices = tf.config.list_logical_devices('GPU')\n",
    "#   assert len(logical_devices) == len(physical_devices) + 1\n",
    "\n",
    "#   tf.config.set_logical_device_configuration(\n",
    "#     physical_devices[0],\n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=10),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=10)])\n",
    "# except:\n",
    "#   # Invalid device or cannot modify logical devices once initialized.\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2589e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights logs/000/ep035-loss0.001-val_acc0.759.h5.\n"
     ]
    }
   ],
   "source": [
    "weights_path=None\n",
    "weights_path=\"logs/000/ep035-loss0.001-val_acc0.759.h5\"\n",
    "if weights_path:\n",
    "    model.load_weights(weights_path, by_name=True)#, skip_mismatch=True)\n",
    "    print('Load weights {}.'.format(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baeb804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22212/896245964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   2481\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_write_train_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2483\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_keras_model_train_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2484\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_write_train_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_steps_per_second\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_write_keras_model_train_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2312\u001b[0m         \u001b[1;31m# If the train_function is a `tf.function`, we can write out a graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'function_spec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2314\u001b[1;33m           \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_write_keras_model_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mgraph\u001b[1;34m(graph_data)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       tensor = ops.convert_to_tensor(\n\u001b[1;32m-> 1063\u001b[1;33m           _serialize_graph(graph_data), dtypes.string)\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       raise ValueError(\"Argument 'graph_data' is not tf.Graph or \"\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36m_serialize_graph\u001b[1;34m(arbitrary_graph)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_serialize_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marbitrary_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marbitrary_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marbitrary_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marbitrary_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   3590\u001b[0m     \"\"\"\n\u001b[0;32m   3591\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3592\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3593\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   3514\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3515\u001b[0m             node.attr[\"_output_shapes\"].list.shape.extend(\n\u001b[1;32m-> 3516\u001b[1;33m                 [output.get_shape().as_proto() for output in op.outputs])\n\u001b[0m\u001b[0;32m   3517\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfunction_def\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3518\u001b[0m           \u001b[0mdefined_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunction_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3514\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3515\u001b[0m             node.attr[\"_output_shapes\"].list.shape.extend(\n\u001b[1;32m-> 3516\u001b[1;33m                 [output.get_shape().as_proto() for output in op.outputs])\n\u001b[0m\u001b[0;32m   3517\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfunction_def\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3518\u001b[0m           \u001b[0mdefined_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunction_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mas_proto\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1231\u001b[0m       return tensor_shape_pb2.TensorShapeProto(dim=[\n\u001b[0;32m   1232\u001b[0m           tensor_shape_pb2.TensorShapeProto.Dim(\n\u001b[1;32m-> 1233\u001b[1;33m               size=-1 if d.value is None else d.value) for d in self._dims\n\u001b[0m\u001b[0;32m   1234\u001b[0m       ])\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1231\u001b[0m       return tensor_shape_pb2.TensorShapeProto(dim=[\n\u001b[0;32m   1232\u001b[0m           tensor_shape_pb2.TensorShapeProto.Dim(\n\u001b[1;32m-> 1233\u001b[1;33m               size=-1 if d.value is None else d.value) for d in self._dims\n\u001b[0m\u001b[0;32m   1234\u001b[0m       ])\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(tfdataset_mapped_train, \n",
    "#                     validation_data=tfdataset_mapped_val,\n",
    "#                   steps_per_epoch=num_train // batch_size,\n",
    "                    epochs=total_epoch,\n",
    "                    initial_epoch=init_epoch,\n",
    "                    workers=1,\n",
    "                    use_multiprocessing=True,\n",
    "                    max_queue_size=10,                    \n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b194006",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback.model = model\n",
    "eval_callback.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676818eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import hourglass_predict_keras, post_process_heatmap_simple\n",
    "heatmap = hourglass_predict_keras(model, data_item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd106a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_heatmap_simple(heatmap, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_map = heatmap[:, :,:, 0]\n",
    "np.where(_map == _map.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5822d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset_mapped_val.element_spec[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791fc69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
